{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/dz3/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = train['label']\n",
    "x_data = train.drop(\"label\", axis=1)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_data, y_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standardized_x_train = StandardScaler().fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained variance ratio = 0.3894352123182725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standardized_x_train = StandardScaler().fit_transform(x_train)\n",
    "\n",
    "pca_train = PCA(20)\n",
    "pca_data = pca_train.fit_transform(standardized_x_train)\n",
    "\n",
    "print(\"explained variance ratio = {}\".format(np.sum(pca_train.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "y_train_bin = label_binarize(y_train, classes=np.arange(y_train.max()))\n",
    "\n",
    "indexes = np.arange(len(x_train), dtype=int)\n",
    "np.random.shuffle(indexes)\n",
    "x_local = pca_data[indexes[:4000]]\n",
    "y_local_bin = y_train_bin[indexes[:4000]]\n",
    "\n",
    "clf = OneVsRestClassifier(SVC()).fit(x_local, y_local_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_x_valid = StandardScaler().fit_transform(x_valid)\n",
    "\n",
    "pca_valid = pca_train.transform(standardized_x_valid)\n",
    "predict_y = clf.predict(pca_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8796428571428572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_valid_bin = label_binarize(y_valid, classes=np.arange(y_valid.max()))\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_valid_bin, predict_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained variance ratio = 0.3894352123182725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standardized_x_train = StandardScaler().fit_transform(x_train)\n",
    "\n",
    "pca_train = PCA(20)\n",
    "pca_data = pca_train.fit_transform(standardized_x_train)\n",
    "\n",
    "print(\"explained variance ratio = {}\".format(np.sum(pca_train.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "indexes = np.arange(len(x_train), dtype=int)\n",
    "np.random.shuffle(indexes)\n",
    "x_local = pca_data[indexes[:4000]]\n",
    "y_local = np.array(y_train)[indexes[:4000]]\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 500)\n",
    "forest = forest.fit(x_local, y_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_x_valid = StandardScaler().fit_transform(x_valid)\n",
    "\n",
    "pca_valid = pca_train.transform(standardized_x_valid)\n",
    "predict_y = forest.predict(pca_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_valid_bin = label_binarize(y_valid, classes=np.arange(y_valid.max()))\n",
    "predict_y_bin = label_binarize(predict_y, classes=np.arange(predict_y.max()))\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_valid_bin, predict_y_bin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "better result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocessor = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('feature_selection', SelectKBest(score_func=mutual_info_classif, k=100)), \n",
    "    ('pca', PCA(n_components=30))])\n",
    "\n",
    "x_train_processed = preprocessor.fit_transform(x_train, y_train)    \n",
    "x_valid_processed = preprocessor.transform(x_valid)\n",
    "y_train_bin = label_binarize(y_train, classes=np.arange(y_train.max()))\n",
    "y_valid_bin = label_binarize(y_valid, classes=np.arange(y_valid.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9267\n"
     ]
    }
   ],
   "source": [
    "svm = OneVsRestClassifier(SVC(kernel='rbf', C=10))\n",
    "svm.fit(x_train_processed, y_train_bin)\n",
    "svm_pred = svm.predict(x_valid_processed)\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_valid_bin, svm_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8985\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "forest.fit(x_train_processed, y_train)\n",
    "rf_pred = forest.predict(x_valid_processed)\n",
    "rf_pred_bin = label_binarize(rf_pred, classes=np.arange(rf_pred.max()))\n",
    "print(f\"Random Forest Accuracy: {accuracy_score(y_valid_bin, rf_pred_bin):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "somehow worse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better score with custop fitures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/dz3/train.csv')\n",
    "y_data = train['label']\n",
    "x_data = train.drop(\"label\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_reshaped = x_data.values.reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mnist_features(images):\n",
    "    features = []\n",
    "    for image in images:\n",
    "        # Calculate horizontal and vertical symmetry\n",
    "        h_symmetry = np.mean(np.abs(image - np.fliplr(image)))\n",
    "        v_symmetry = np.mean(np.abs(image - np.flipud(image)))\n",
    "        \n",
    "        # Calculate center of mass\n",
    "        y_coord, x_coord = np.indices(image.shape)\n",
    "        total_mass = image.sum()\n",
    "        if total_mass == 0:\n",
    "            com_y, com_x = image.shape[0]/2, image.shape[1]/2\n",
    "        else:\n",
    "            com_y = np.sum(y_coord * image) / total_mass\n",
    "            com_x = np.sum(x_coord * image) / total_mass\n",
    "        \n",
    "        # Add number of pixels above mean intensity\n",
    "        mean_intensity = np.mean(image)\n",
    "        active_pixels = np.sum(image > mean_intensity)\n",
    "        \n",
    "        features.append([h_symmetry, v_symmetry, com_y, com_x, active_pixels])\n",
    "    \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_features = extract_mnist_features(x_data_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_combined = np.hstack([\n",
    "    x_data,  \n",
    "    mnist_features * 10\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_combined, y_data, test_size=0.2, random_state=42, stratify=y_data\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance with 50 components: 0.5606\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=50) \n",
    "x_train_pca = pca.fit_transform(x_train_scaled)\n",
    "x_valid_pca = pca.transform(x_valid_scaled)\n",
    "print(f\"Explained variance with 50 components: {pca.explained_variance_ratio_.sum():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9702\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='rbf', C=5, gamma='scale')\n",
    "svm.fit(x_train_pca, y_train)\n",
    "svm_pred = svm.predict(x_valid_pca)\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_valid, svm_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pretty cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9435\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_features='sqrt',\n",
    "    min_samples_split=4,\n",
    "    max_depth=None,\n",
    "    n_jobs=-1\n",
    ")\n",
    "forest.fit(x_train_pca, y_train)\n",
    "rf_pred = forest.predict(x_valid_pca)\n",
    "print(f\"Random Forest Accuracy: {accuracy_score(y_valid, rf_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nit great"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
